{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvW5ujdU-r9e"
      },
      "source": [
        "# Import the necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "VG1wtHQx-r9f"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from pathlib import Path\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*  torch and torch.nn: PyTorch core and neural network layers.\n",
        "*  torchvision.datasets/transforms: Convenient datasets and image preprocessing\n",
        "*  matplotlib: Not used later, but typically for plotting (safe to remove in this notebook).\n",
        "*  tqdm: Pretty progress bars for training/testing loops. pathlib / os: File handling utilities.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5V9MbDXk1kld"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1dE4PbN-r9f"
      },
      "source": [
        "# Load the MNIST dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "lwjJ3AVK-r9f"
      },
      "outputs": [],
      "source": [
        "# Make torch deterministic and sets a random seed\n",
        "_ = torch.manual_seed(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "JQ_9ZFDj-r9f"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
        "\n",
        "# Load the MNIST dataset\n",
        "mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "# Create a dataloader for the training\n",
        "train_loader = torch.utils.data.DataLoader(mnist_trainset, batch_size=10, shuffle=True)\n",
        "\n",
        "# Load the MNIST test set\n",
        "mnist_testset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "test_loader = torch.utils.data.DataLoader(mnist_testset, batch_size=10, shuffle=True)\n",
        "\n",
        "# Define the device\n",
        "device = \"cpu\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ToTensor() converts PIL images to tensors (values in [0,1]).\n",
        "Normalize(mean, std) standardizes images using MNIST’s mean/std (~0.13/0.31). This helps training converge.\n",
        "\n",
        "Loads training set (downloads if missing) and wraps it in a DataLoader:\n",
        "batch_size=10: the number of images per step.\n",
        "shuffle=True: mix the order each epoch for better training.\n",
        "\n",
        "QAT → quantized inference is primarily supported on CPU in PyTorch. So we keep it on CPU.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "tGLSTtpo18-z"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mh6wPpNL-r9g"
      },
      "source": [
        "# Define the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "4-xBZxt1-r9g"
      },
      "outputs": [],
      "source": [
        "class VerySimpleNet(nn.Module):\n",
        "    def __init__(self, hidden_size_1=100, hidden_size_2=100):\n",
        "        super(VerySimpleNet,self).__init__()\n",
        "        self.quant = torch.quantization.QuantStub()\n",
        "        self.linear1 = nn.Linear(28*28, hidden_size_1)\n",
        "        self.linear2 = nn.Linear(hidden_size_1, hidden_size_2)\n",
        "        self.linear3 = nn.Linear(hidden_size_2, 10)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dequant = torch.quantization.DeQuantStub()\n",
        "\n",
        "    def forward(self, img):\n",
        "        x = img.view(-1, 28*28)\n",
        "        x = self.quant(x)\n",
        "        x = self.relu(self.linear1(x))\n",
        "        x = self.relu(self.linear2(x))\n",
        "        x = self.linear3(x)\n",
        "        x = self.dequant(x)\n",
        "        return x\n",
        "\n",
        "net = VerySimpleNet().to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What’s happening here?\n",
        "\n",
        "This is a simple MLP for MNIST:\n",
        "\n",
        "Input: 28×28 = 784 pixels → flatten to a vector\n",
        "Two hidden layers (Linear + ReLU)\n",
        "Output: 10 logits (digits 0…9)\n",
        "\n",
        "\n",
        "\n",
        "Why QuantStub and DeQuantStub?\n",
        "Simulating the quantization for weight and biases.\n",
        "\n",
        "QuantStub() and DeQuantStub() mark where quantization starts and ends.\n",
        "During training with QAT:\n",
        "\n",
        "QuantStub inserts observers and fake quantization at the input to simulate the\n",
        "full precision weights.\n",
        "\n",
        "Layers in between will be trained with simulated INT8 behavior.\n",
        "DeQuantStub converts the output back to FP32 (so losses work normally)."
      ],
      "metadata": {
        "id": "97UwUQiB6Vac"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ksdWQGEp-r9g"
      },
      "source": [
        "# Insert min-max observers in the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k7GRw8w9-r9g",
        "outputId": "e6f3dc6a-5232-495d-b044-d532c09e6a23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1959560408.py:3: DeprecationWarning: torch.ao.quantization is deprecated and will be removed in 2.10. \n",
            "For migrations of users: \n",
            "1. Eager mode quantization (torch.ao.quantization.quantize, torch.ao.quantization.quantize_dynamic), please migrate to use torchao eager mode quantize_ API instead \n",
            "2. FX graph mode quantization (torch.ao.quantization.quantize_fx.prepare_fx,torch.ao.quantization.quantize_fx.convert_fx, please migrate to use torchao pt2e quantization API instead (prepare_pt2e, convert_pt2e) \n",
            "3. pt2e quantization has been migrated to torchao (https://github.com/pytorch/ao/tree/main/torchao/quantization/pt2e) \n",
            "see https://github.com/pytorch/ao/issues/2259 for more details\n",
            "  net_quantized = torch.ao.quantization.prepare_qat(net) # Insert observers\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VerySimpleNet(\n",
              "  (quant): QuantStub(\n",
              "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "  )\n",
              "  (linear1): Linear(\n",
              "    in_features=784, out_features=100, bias=True\n",
              "    (weight_fake_quant): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "  )\n",
              "  (linear2): Linear(\n",
              "    in_features=100, out_features=100, bias=True\n",
              "    (weight_fake_quant): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "  )\n",
              "  (linear3): Linear(\n",
              "    in_features=100, out_features=10, bias=True\n",
              "    (weight_fake_quant): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "  )\n",
              "  (relu): ReLU()\n",
              "  (dequant): DeQuantStub()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "net.qconfig = torch.ao.quantization.default_qconfig\n",
        "net.train()\n",
        "net_quantized = torch.ao.quantization.prepare_qat(net) # Insert observers\n",
        "net_quantized"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "qconfig: Defines how to quantify activations and weights:\n",
        "\n",
        "What kind of observer to use (e.g., MinMax)\n",
        "Fake‑quant modules to simulate INT8 during training\n",
        "\n",
        "\n",
        "prepare_qat(model):\n",
        "\n",
        "Inserts observers and fake‑quant modules into the model (at places like stubs and supported layers)."
      ],
      "metadata": {
        "id": "h1_X4CTR8o3T"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cQmTNVg-r9g"
      },
      "source": [
        "# Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CqVWXR27-r9g",
        "outputId": "ac807738-3202-40eb-a5eb-2241855429c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|██████████| 6000/6000 [00:49<00:00, 120.72it/s, loss=0.224]\n"
          ]
        }
      ],
      "source": [
        "def train(train_loader, net, epochs=5, total_iterations_limit=None):\n",
        "    cross_el = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
        "\n",
        "    total_iterations = 0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        net.train()\n",
        "\n",
        "        loss_sum = 0\n",
        "        num_iterations = 0\n",
        "\n",
        "        data_iterator = tqdm(train_loader, desc=f'Epoch {epoch+1}')\n",
        "        if total_iterations_limit is not None:\n",
        "            data_iterator.total = total_iterations_limit\n",
        "        for data in data_iterator:\n",
        "            num_iterations += 1\n",
        "            total_iterations += 1\n",
        "            x, y = data\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = net(x.view(-1, 28*28))\n",
        "            loss = cross_el(output, y)\n",
        "            loss_sum += loss.item()\n",
        "            avg_loss = loss_sum / num_iterations\n",
        "            data_iterator.set_postfix(loss=avg_loss)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if total_iterations_limit is not None and total_iterations >= total_iterations_limit:\n",
        "                return\n",
        "\n",
        "def print_size_of_model(model):\n",
        "    torch.save(model.state_dict(), \"temp_delme.p\")\n",
        "    print('Size (KB):', os.path.getsize(\"temp_delme.p\")/1e3)\n",
        "    os.remove('temp_delme.p')\n",
        "\n",
        "train(train_loader, net_quantized, epochs=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Uses CrossEntropyLoss for classification and Adam optimizer.\n",
        "Inside the loop:\n",
        "\n",
        "Flatten input (view(-1, 28*28))\n",
        "Forward pass through the QAT‑prepared model → fake quant applies\n",
        "Compute loss, backprop, and update weights\n",
        "Uses tqdm to display average loss nicely\n",
        "\n",
        "\n",
        "\n",
        "The crucial part: this training happens with fake quantization in place, so the model learns quantization‑friendly weights."
      ],
      "metadata": {
        "id": "aA4603Zw82-z"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZUJeKqOJ-r9g"
      },
      "source": [
        "# Define the testing loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "bBd-YM2q-r9g"
      },
      "outputs": [],
      "source": [
        "def test(model: nn.Module, total_iterations: int = None):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    iterations = 0\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in tqdm(test_loader, desc='Testing'):\n",
        "            x, y = data\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "            output = model(x.view(-1, 784))\n",
        "            for idx, i in enumerate(output):\n",
        "                if torch.argmax(i) == y[idx]:\n",
        "                    correct +=1\n",
        "                total +=1\n",
        "            iterations += 1\n",
        "            if total_iterations is not None and iterations >= total_iterations:\n",
        "                break\n",
        "    print(f'Accuracy: {round(correct/total, 3)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_SH4SSh7-r9g"
      },
      "source": [
        "# Check the collected statistics during training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4CK95Ad7-r9g",
        "outputId": "b4987221-bad4-4b70-88e1-bbc3590d3db8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Check statistics of the various layers\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VerySimpleNet(\n",
              "  (quant): QuantStub(\n",
              "    (activation_post_process): MinMaxObserver(min_val=-0.4242129623889923, max_val=2.821486711502075)\n",
              "  )\n",
              "  (linear1): Linear(\n",
              "    in_features=784, out_features=100, bias=True\n",
              "    (weight_fake_quant): MinMaxObserver(min_val=-0.4810347855091095, max_val=0.3415062427520752)\n",
              "    (activation_post_process): MinMaxObserver(min_val=-40.239410400390625, max_val=39.7955436706543)\n",
              "  )\n",
              "  (linear2): Linear(\n",
              "    in_features=100, out_features=100, bias=True\n",
              "    (weight_fake_quant): MinMaxObserver(min_val=-0.43307897448539734, max_val=0.3635982275009155)\n",
              "    (activation_post_process): MinMaxObserver(min_val=-41.65215301513672, max_val=22.231578826904297)\n",
              "  )\n",
              "  (linear3): Linear(\n",
              "    in_features=100, out_features=10, bias=True\n",
              "    (weight_fake_quant): MinMaxObserver(min_val=-0.5131738185882568, max_val=0.20312127470970154)\n",
              "    (activation_post_process): MinMaxObserver(min_val=-32.679283142089844, max_val=22.15723419189453)\n",
              "  )\n",
              "  (relu): ReLU()\n",
              "  (dequant): DeQuantStub()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "print(f'Check statistics of the various layers')\n",
        "net_quantized"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DhS01kqd-r9h"
      },
      "source": [
        "# Quantize the model using the statistics collected"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MW3MwfdD-r9h",
        "outputId": "2d3f0fc5-ccbd-4e93-bb63-1aa8b9f5a593"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-709763000.py:2: DeprecationWarning: torch.ao.quantization is deprecated and will be removed in 2.10. \n",
            "For migrations of users: \n",
            "1. Eager mode quantization (torch.ao.quantization.quantize, torch.ao.quantization.quantize_dynamic), please migrate to use torchao eager mode quantize_ API instead \n",
            "2. FX graph mode quantization (torch.ao.quantization.quantize_fx.prepare_fx,torch.ao.quantization.quantize_fx.convert_fx, please migrate to use torchao pt2e quantization API instead (prepare_pt2e, convert_pt2e) \n",
            "3. pt2e quantization has been migrated to torchao (https://github.com/pytorch/ao/tree/main/torchao/quantization/pt2e) \n",
            "see https://github.com/pytorch/ao/issues/2259 for more details\n",
            "  net_quantized = torch.ao.quantization.convert(net_quantized)\n"
          ]
        }
      ],
      "source": [
        "net_quantized.eval()\n",
        "net_quantized = torch.ao.quantization.convert(net_quantized)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97wPFKuC-r9h",
        "outputId": "9d579a4e-3d66-434d-98df-579def66f879"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Check statistics of the various layers\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VerySimpleNet(\n",
              "  (quant): Quantize(scale=tensor([0.0256]), zero_point=tensor([17]), dtype=torch.quint8)\n",
              "  (linear1): QuantizedLinear(in_features=784, out_features=100, scale=0.6301965117454529, zero_point=64, qscheme=torch.per_tensor_affine)\n",
              "  (linear2): QuantizedLinear(in_features=100, out_features=100, scale=0.5030215382575989, zero_point=83, qscheme=torch.per_tensor_affine)\n",
              "  (linear3): QuantizedLinear(in_features=100, out_features=10, scale=0.4317835867404938, zero_point=76, qscheme=torch.per_tensor_affine)\n",
              "  (relu): ReLU()\n",
              "  (dequant): DeQuantize()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "print(f'Check statistics of the various layers')\n",
        "net_quantized"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJPzU2t5-r9h"
      },
      "source": [
        "# Print weights and size of the model after quantization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pU2nhr5u-r9h",
        "outputId": "d2450665-eaf0-49ca-8a83-10072893e25b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weights before quantization\n",
            "tensor([[  3,   8,  -5,  ...,   9,   4,   4],\n",
            "        [ -5,  -4,  -3,  ...,  -5,  -2,  -8],\n",
            "        [  0,   9,  -4,  ...,   0,   5,   7],\n",
            "        ...,\n",
            "        [  4,   5,  -4,  ...,  -5,   0, -10],\n",
            "        [ -5,  -3,   6,  ...,   1,   1,   1],\n",
            "        [  3,   2,  -2,  ...,   8,  -5,   0]], dtype=torch.int8)\n"
          ]
        }
      ],
      "source": [
        "# Print the weights matrix of the model before quantization\n",
        "print('Weights before quantization')\n",
        "print(torch.int_repr(net_quantized.linear1.weight()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNHnPX4x-r9h",
        "outputId": "c2450564-1a4d-466e-c70d-69997589d3e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing the model after quantization\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing: 100%|██████████| 1000/1000 [00:03<00:00, 293.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.957\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "print('Testing the model after quantization')\n",
        "test(net_quantized)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Before conversion\n",
        "print(\"Accuracy before convert (QAT prepared):\")\n",
        "print(net_quantized)\n",
        "test(net_quantized)\n",
        "\n",
        "# Compare sizes\n",
        "print(\"FP32 model size:\")\n",
        "print_size_of_model(net)\n",
        "\n",
        "# Convert to INT8\n",
        "net_quantized.eval()\n",
        "net_int8 = torch.ao.quantization.convert(net_quantized)\n",
        "\n",
        "print(\"INT8 model size:\")\n",
        "print_size_of_model(net_int8)\n",
        "\n",
        "# After conversion\n",
        "print(\"Accuracy after convert (INT8):\")\n",
        "test(net_int8)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_U2Q33HEBQ2",
        "outputId": "392994e8-b74a-43dc-b8c0-a524f3442d99"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy before convert (QAT prepared):\n",
            "VerySimpleNet(\n",
            "  (quant): QuantStub(\n",
            "    (activation_post_process): MinMaxObserver(min_val=-0.4242129623889923, max_val=2.821486711502075)\n",
            "  )\n",
            "  (linear1): Linear(\n",
            "    in_features=784, out_features=100, bias=True\n",
            "    (weight_fake_quant): MinMaxObserver(min_val=-0.4810347855091095, max_val=0.3415062427520752)\n",
            "    (activation_post_process): MinMaxObserver(min_val=-41.82633590698242, max_val=39.7955436706543)\n",
            "  )\n",
            "  (linear2): Linear(\n",
            "    in_features=100, out_features=100, bias=True\n",
            "    (weight_fake_quant): MinMaxObserver(min_val=-0.43307897448539734, max_val=0.3635982275009155)\n",
            "    (activation_post_process): MinMaxObserver(min_val=-41.65215301513672, max_val=22.231578826904297)\n",
            "  )\n",
            "  (linear3): Linear(\n",
            "    in_features=100, out_features=10, bias=True\n",
            "    (weight_fake_quant): MinMaxObserver(min_val=-0.5131738185882568, max_val=0.20312127470970154)\n",
            "    (activation_post_process): MinMaxObserver(min_val=-32.679283142089844, max_val=22.15723419189453)\n",
            "  )\n",
            "  (relu): ReLU()\n",
            "  (dequant): DeQuantStub()\n",
            ")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing: 100%|██████████| 1000/1000 [00:03<00:00, 303.69it/s]\n",
            "/tmp/ipython-input-3940987492.py:12: DeprecationWarning: torch.ao.quantization is deprecated and will be removed in 2.10. \n",
            "For migrations of users: \n",
            "1. Eager mode quantization (torch.ao.quantization.quantize, torch.ao.quantization.quantize_dynamic), please migrate to use torchao eager mode quantize_ API instead \n",
            "2. FX graph mode quantization (torch.ao.quantization.quantize_fx.prepare_fx,torch.ao.quantization.quantize_fx.convert_fx, please migrate to use torchao pt2e quantization API instead (prepare_pt2e, convert_pt2e) \n",
            "3. pt2e quantization has been migrated to torchao (https://github.com/pytorch/ao/tree/main/torchao/quantization/pt2e) \n",
            "see https://github.com/pytorch/ao/issues/2259 for more details\n",
            "  net_int8 = torch.ao.quantization.convert(net_quantized)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.958\n",
            "FP32 model size:\n",
            "Size (KB): 361.465\n",
            "INT8 model size:\n",
            "Size (KB): 95.797\n",
            "Accuracy after convert (INT8):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing: 100%|██████████| 1000/1000 [00:03<00:00, 276.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.957\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "thw_3YpQGsJ8"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "pytorch-cuda",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}