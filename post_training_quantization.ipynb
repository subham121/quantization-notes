{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mT7s_8jl-iko"
      },
      "source": [
        "# Import the necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Ey1Rn9qY-ikq"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from pathlib import Path\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bnb7LMQs-ikr"
      },
      "source": [
        "# Load the MNIST dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "jVPkNyfa-ikr"
      },
      "outputs": [],
      "source": [
        "# Make torch deterministic\n",
        "_ = torch.manual_seed(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "sUTTH7nr-iks",
        "outputId": "f3d9afbb-e286-44d7-90a8-4fabd200a7f7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 17.8MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 488kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 4.50MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 4.54MB/s]\n"
          ]
        }
      ],
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
        "\n",
        "# Load the MNIST dataset\n",
        "mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "# Create a dataloader for the training\n",
        "train_loader = torch.utils.data.DataLoader(mnist_trainset, batch_size=10, shuffle=True)\n",
        "\n",
        "# Load the MNIST test set\n",
        "mnist_testset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "test_loader = torch.utils.data.DataLoader(mnist_testset, batch_size=10, shuffle=True)\n",
        "\n",
        "# Define the device\n",
        "device = \"cpu\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ToTensor() converts PIL images to tensors (values in [0,1]). Normalize(mean, std) standardizes images using MNIST’s mean/std (~0.13/0.31). This helps training converge.\n",
        "\n",
        "Loads training set (downloads if missing) and wraps it in a DataLoader: batch_size=10: the number of images per step. shuffle=True: mix the order each epoch for better training.\n",
        "\n",
        "Loads the training set, making batches of 10 and shuffling them each epoch.\n",
        "\n",
        "Loads the test set similarly.\n",
        "\n",
        "Quantized inference in PyTorch is primarily supported on CPU, so keep the model on CPU.\n",
        "\n"
      ],
      "metadata": {
        "id": "9XWxAqmyLC2Y"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvJ5WuoK-iks"
      },
      "source": [
        "# Define the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "9PYj2RK_-ikt"
      },
      "outputs": [],
      "source": [
        "class VerySimpleNet(nn.Module):\n",
        "    def __init__(self, hidden_size_1=100, hidden_size_2=100):\n",
        "        super(VerySimpleNet,self).__init__()\n",
        "        self.linear1 = nn.Linear(28*28, hidden_size_1)\n",
        "        self.linear2 = nn.Linear(hidden_size_1, hidden_size_2)\n",
        "        self.linear3 = nn.Linear(hidden_size_2, 10)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, img):\n",
        "        x = img.view(-1, 28*28)\n",
        "        x = self.relu(self.linear1(x))\n",
        "        x = self.relu(self.linear2(x))\n",
        "        x = self.linear3(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "mumDsSVj-ikt"
      },
      "outputs": [],
      "source": [
        "net = VerySimpleNet().to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a simple MLP with two hidden layers and ReLU activations, producing logits for 10 classes (digits 0–9).\n",
        "\n",
        "No quantization stubs here because we first train a normal FP32 model.\n",
        "\n",
        "Instantiates and moves it to CPU.\n",
        "\n"
      ],
      "metadata": {
        "id": "3W6JOA8dLTDs"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VzRg6TFn-ikt"
      },
      "source": [
        "# Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "b7oD_HZu-ikt",
        "outputId": "a650a618-ed3b-4b93-f6f3-da577b559040",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|██████████| 6000/6000 [00:51<00:00, 117.43it/s, loss=0.223]\n"
          ]
        }
      ],
      "source": [
        "def train(train_loader, net, epochs=5, total_iterations_limit=None):\n",
        "    cross_el = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
        "\n",
        "    total_iterations = 0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        net.train()\n",
        "\n",
        "        loss_sum = 0\n",
        "        num_iterations = 0\n",
        "\n",
        "        data_iterator = tqdm(train_loader, desc=f'Epoch {epoch+1}')\n",
        "        if total_iterations_limit is not None:\n",
        "            data_iterator.total = total_iterations_limit\n",
        "        for data in data_iterator:\n",
        "            num_iterations += 1\n",
        "            total_iterations += 1\n",
        "            x, y = data\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = net(x.view(-1, 28*28))\n",
        "            loss = cross_el(output, y)\n",
        "            loss_sum += loss.item()\n",
        "            avg_loss = loss_sum / num_iterations\n",
        "            data_iterator.set_postfix(loss=avg_loss)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if total_iterations_limit is not None and total_iterations >= total_iterations_limit:\n",
        "                return\n",
        "\n",
        "def print_size_of_model(model):\n",
        "    torch.save(model.state_dict(), \"temp_delme.p\")\n",
        "    print('Size (KB):', os.path.getsize(\"temp_delme.p\")/1e3)\n",
        "    os.remove('temp_delme.p')\n",
        "\n",
        "MODEL_FILENAME = 'simplenet_ptq.pt'\n",
        "\n",
        "if Path(MODEL_FILENAME).exists():\n",
        "    net.load_state_dict(torch.load(MODEL_FILENAME))\n",
        "    print('Loaded model from disk')\n",
        "else:\n",
        "    train(train_loader, net, epochs=1)\n",
        "    # Save the model to disk\n",
        "    torch.save(net.state_dict(), MODEL_FILENAME)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is where we train the Baseline FP32 Model\n",
        "\n",
        "Standard training loop:\n",
        "\n",
        "CrossEntropyLoss for classification,\n",
        "Adam optimizer,\n",
        "Flatten inputs, forward pass, compute loss, backprop, and update.\n",
        "tqdm shows average loss."
      ],
      "metadata": {
        "id": "DKhawW95LcvD"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSiPeqhU-ikt"
      },
      "source": [
        "# Define the testing loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "WoKPap07-ikt"
      },
      "outputs": [],
      "source": [
        "def test(model: nn.Module, total_iterations: int = None):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    iterations = 0\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in tqdm(test_loader, desc='Testing'):\n",
        "            x, y = data\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "            output = model(x.view(-1, 784))\n",
        "            for idx, i in enumerate(output):\n",
        "                if torch.argmax(i) == y[idx]:\n",
        "                    correct +=1\n",
        "                total +=1\n",
        "            iterations += 1\n",
        "            if total_iterations is not None and iterations >= total_iterations:\n",
        "                break\n",
        "    print(f'Accuracy: {round(correct/total, 3)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluation mode, no gradients.\n",
        "Flattens input and compares predicted class (argmax) to label.\n",
        "Prints accuracy."
      ],
      "metadata": {
        "id": "F6v3_fayL7Gc"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uuf0e9XI-iku"
      },
      "source": [
        "# Print weights and size of the model before quantization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "pANFjOGe-iku",
        "outputId": "f41003b4-cdd4-469f-f3a0-24e68efbe2bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weights before quantization\n",
            "Parameter containing:\n",
            "tensor([[ 0.0046,  0.0240, -0.0246,  ...,  0.0268,  0.0086,  0.0069],\n",
            "        [-0.0242, -0.0194, -0.0149,  ..., -0.0247, -0.0104, -0.0344],\n",
            "        [ 0.0268,  0.0618,  0.0137,  ...,  0.0266,  0.0481,  0.0550],\n",
            "        ...,\n",
            "        [ 0.0458,  0.0495,  0.0149,  ...,  0.0095,  0.0288, -0.0082],\n",
            "        [-0.0129, -0.0048,  0.0273,  ...,  0.0076,  0.0076,  0.0071],\n",
            "        [ 0.0335,  0.0282,  0.0140,  ...,  0.0504,  0.0011,  0.0213]],\n",
            "       requires_grad=True)\n",
            "torch.float32\n"
          ]
        }
      ],
      "source": [
        "# Print the weights matrix of the model before quantization\n",
        "print('Weights before quantization')\n",
        "print(net.linear1.weight)\n",
        "print(net.linear1.weight.dtype)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "lDYin0sV-iku",
        "outputId": "d3ab3d42-1f03-4797-a57a-35f18bb54b97",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of the model before quantization\n",
            "Size (KB): 361.401\n"
          ]
        }
      ],
      "source": [
        "print('Size of the model before quantization')\n",
        "print_size_of_model(net)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "_5UDpSiH-iku",
        "outputId": "6a678296-39d2-462c-ff64-d9b9f118cbf7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the model before quantization: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing: 100%|██████████| 1000/1000 [00:06<00:00, 155.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.962\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "print(f'Accuracy of the model before quantization: ')\n",
        "test(net)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5ZVaxit-iku"
      },
      "source": [
        "# Insert min-max observers in the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "qbPvHWZp-iku"
      },
      "outputs": [],
      "source": [
        "class QuantizedVerySimpleNet(nn.Module):\n",
        "    def __init__(self, hidden_size_1=100, hidden_size_2=100):\n",
        "        super(QuantizedVerySimpleNet,self).__init__()\n",
        "        self.quant = torch.quantization.QuantStub()\n",
        "        self.linear1 = nn.Linear(28*28, hidden_size_1)\n",
        "        self.linear2 = nn.Linear(hidden_size_1, hidden_size_2)\n",
        "        self.linear3 = nn.Linear(hidden_size_2, 10)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dequant = torch.quantization.DeQuantStub()\n",
        "\n",
        "    def forward(self, img):\n",
        "        x = img.view(-1, 28*28)\n",
        "        x = self.quant(x)\n",
        "        x = self.relu(self.linear1(x))\n",
        "        x = self.relu(self.linear2(x))\n",
        "        x = self.linear3(x)\n",
        "        x = self.dequant(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ZBlYvIXW-iku",
        "outputId": "cdcef655-9764-47b0-b6d8-4e674aa42ec2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1743408182.py:7: DeprecationWarning: torch.ao.quantization is deprecated and will be removed in 2.10. \n",
            "For migrations of users: \n",
            "1. Eager mode quantization (torch.ao.quantization.quantize, torch.ao.quantization.quantize_dynamic), please migrate to use torchao eager mode quantize_ API instead \n",
            "2. FX graph mode quantization (torch.ao.quantization.quantize_fx.prepare_fx,torch.ao.quantization.quantize_fx.convert_fx, please migrate to use torchao pt2e quantization API instead (prepare_pt2e, convert_pt2e) \n",
            "3. pt2e quantization has been migrated to torchao (https://github.com/pytorch/ao/tree/main/torchao/quantization/pt2e) \n",
            "see https://github.com/pytorch/ao/issues/2259 for more details\n",
            "  net_quantized = torch.ao.quantization.prepare(net_quantized) # Insert observers\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "QuantizedVerySimpleNet(\n",
              "  (quant): QuantStub(\n",
              "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "  )\n",
              "  (linear1): Linear(\n",
              "    in_features=784, out_features=100, bias=True\n",
              "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "  )\n",
              "  (linear2): Linear(\n",
              "    in_features=100, out_features=100, bias=True\n",
              "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "  )\n",
              "  (linear3): Linear(\n",
              "    in_features=100, out_features=10, bias=True\n",
              "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "  )\n",
              "  (relu): ReLU()\n",
              "  (dequant): DeQuantStub()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "net_quantized = QuantizedVerySimpleNet().to(device)\n",
        "# Copy weights from unquantized model\n",
        "net_quantized.load_state_dict(net.state_dict())\n",
        "net_quantized.eval()\n",
        "\n",
        "net_quantized.qconfig = torch.ao.quantization.default_qconfig\n",
        "net_quantized = torch.ao.quantization.prepare(net_quantized) # Insert observers\n",
        "net_quantized"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vsnj1kWN-iku"
      },
      "source": [
        "# Calibrate the model using the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "gpvuJTEq-iku",
        "outputId": "ba89f9f6-2bce-4fdc-ac82-0c79cc290f70",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing: 100%|██████████| 1000/1000 [00:03<00:00, 252.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.962\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "test(net_quantized)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ZLdz94u--iku",
        "outputId": "21ed446e-9a98-47a6-f913-1fca69a21857",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Check statistics of the various layers\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "QuantizedVerySimpleNet(\n",
              "  (quant): QuantStub(\n",
              "    (activation_post_process): MinMaxObserver(min_val=-0.4242129623889923, max_val=2.821486711502075)\n",
              "  )\n",
              "  (linear1): Linear(\n",
              "    in_features=784, out_features=100, bias=True\n",
              "    (activation_post_process): MinMaxObserver(min_val=-54.20774841308594, max_val=38.45577621459961)\n",
              "  )\n",
              "  (linear2): Linear(\n",
              "    in_features=100, out_features=100, bias=True\n",
              "    (activation_post_process): MinMaxObserver(min_val=-26.76471710205078, max_val=23.914104461669922)\n",
              "  )\n",
              "  (linear3): Linear(\n",
              "    in_features=100, out_features=10, bias=True\n",
              "    (activation_post_process): MinMaxObserver(min_val=-28.624492645263672, max_val=20.91961669921875)\n",
              "  )\n",
              "  (relu): ReLU()\n",
              "  (dequant): DeQuantStub()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "print(f'Check statistics of the various layers')\n",
        "net_quantized"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjjcu-HL-iku"
      },
      "source": [
        "# Quantize the model using the statistics collected"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "OqXKc4-x-iku",
        "outputId": "c24e54a3-83ef-491f-b6cc-374d341fe115",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1503456306.py:1: DeprecationWarning: torch.ao.quantization is deprecated and will be removed in 2.10. \n",
            "For migrations of users: \n",
            "1. Eager mode quantization (torch.ao.quantization.quantize, torch.ao.quantization.quantize_dynamic), please migrate to use torchao eager mode quantize_ API instead \n",
            "2. FX graph mode quantization (torch.ao.quantization.quantize_fx.prepare_fx,torch.ao.quantization.quantize_fx.convert_fx, please migrate to use torchao pt2e quantization API instead (prepare_pt2e, convert_pt2e) \n",
            "3. pt2e quantization has been migrated to torchao (https://github.com/pytorch/ao/tree/main/torchao/quantization/pt2e) \n",
            "see https://github.com/pytorch/ao/issues/2259 for more details\n",
            "  net_quantized = torch.ao.quantization.convert(net_quantized)\n"
          ]
        }
      ],
      "source": [
        "net_quantized = torch.ao.quantization.convert(net_quantized)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Cfb27t93-iku",
        "outputId": "c9a28bdc-9735-4722-e108-20d2461a52d1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Check statistics of the various layers\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "QuantizedVerySimpleNet(\n",
              "  (quant): Quantize(scale=tensor([0.0256]), zero_point=tensor([17]), dtype=torch.quint8)\n",
              "  (linear1): QuantizedLinear(in_features=784, out_features=100, scale=0.7296341061592102, zero_point=74, qscheme=torch.per_tensor_affine)\n",
              "  (linear2): QuantizedLinear(in_features=100, out_features=100, scale=0.39904582500457764, zero_point=67, qscheme=torch.per_tensor_affine)\n",
              "  (linear3): QuantizedLinear(in_features=100, out_features=10, scale=0.3901110887527466, zero_point=73, qscheme=torch.per_tensor_affine)\n",
              "  (relu): ReLU()\n",
              "  (dequant): DeQuantize()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "print(f'Check statistics of the various layers')\n",
        "net_quantized"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-SA2m4V-ikv"
      },
      "source": [
        "# Print weights of the model after quantization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "_Req6NWK-ikv",
        "outputId": "1944a4e3-925d-4da3-9b60-7884819fc46e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weights after quantization\n",
            "tensor([[ 1,  5, -6,  ...,  6,  2,  2],\n",
            "        [-5, -4, -3,  ..., -6, -2, -8],\n",
            "        [ 6, 14,  3,  ...,  6, 11, 12],\n",
            "        ...,\n",
            "        [10, 11,  3,  ...,  2,  6, -2],\n",
            "        [-3, -1,  6,  ...,  2,  2,  2],\n",
            "        [ 8,  6,  3,  ..., 11,  0,  5]], dtype=torch.int8)\n"
          ]
        }
      ],
      "source": [
        "# Print the weights matrix of the model after quantization\n",
        "print('Weights after quantization')\n",
        "print(torch.int_repr(net_quantized.linear1.weight()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szwxUyJP-ikv"
      },
      "source": [
        "# Compare the dequantized weights and the original weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "iYXxysyL-ikv",
        "outputId": "060a271c-4532-4251-f1ff-e06bfdc2898c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original weights: \n",
            "Parameter containing:\n",
            "tensor([[ 0.0046,  0.0240, -0.0246,  ...,  0.0268,  0.0086,  0.0069],\n",
            "        [-0.0242, -0.0194, -0.0149,  ..., -0.0247, -0.0104, -0.0344],\n",
            "        [ 0.0268,  0.0618,  0.0137,  ...,  0.0266,  0.0481,  0.0550],\n",
            "        ...,\n",
            "        [ 0.0458,  0.0495,  0.0149,  ...,  0.0095,  0.0288, -0.0082],\n",
            "        [-0.0129, -0.0048,  0.0273,  ...,  0.0076,  0.0076,  0.0071],\n",
            "        [ 0.0335,  0.0282,  0.0140,  ...,  0.0504,  0.0011,  0.0213]],\n",
            "       requires_grad=True)\n",
            "\n",
            "Dequantized weights: \n",
            "tensor([[ 0.0044,  0.0222, -0.0266,  ...,  0.0266,  0.0089,  0.0089],\n",
            "        [-0.0222, -0.0177, -0.0133,  ..., -0.0266, -0.0089, -0.0355],\n",
            "        [ 0.0266,  0.0621,  0.0133,  ...,  0.0266,  0.0488,  0.0532],\n",
            "        ...,\n",
            "        [ 0.0443,  0.0488,  0.0133,  ...,  0.0089,  0.0266, -0.0089],\n",
            "        [-0.0133, -0.0044,  0.0266,  ...,  0.0089,  0.0089,  0.0089],\n",
            "        [ 0.0355,  0.0266,  0.0133,  ...,  0.0488,  0.0000,  0.0222]])\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print('Original weights: ')\n",
        "print(net.linear1.weight)\n",
        "print('')\n",
        "print(f'Dequantized weights: ')\n",
        "print(torch.dequantize(net_quantized.linear1.weight()))\n",
        "print('')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-WtaG3u-ikv"
      },
      "source": [
        "# Print size and accuracy of the quantized model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "ZvTN3vXR-ikv",
        "outputId": "46993a2e-14c0-4271-94ec-d5157e1c709a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of the model after quantization\n",
            "Size (KB): 95.797\n"
          ]
        }
      ],
      "source": [
        "print('Size of the model after quantization')\n",
        "print_size_of_model(net_quantized)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "8iPzrxx7-ikv",
        "outputId": "23a1cc1d-eeff-4fda-d22c-3118f9dd219a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing the model after quantization\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing: 100%|██████████| 1000/1000 [00:04<00:00, 205.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.962\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "print('Testing the model after quantization')\n",
        "test(net_quantized)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n1jfQHysBxBF"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "pytorch-cuda",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}